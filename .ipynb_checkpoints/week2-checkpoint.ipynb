{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        l = []\n",
    "        for line in lines:\n",
    "            l.append(line.strip().split(\"</B>\")[1])\n",
    "#             print(line)\n",
    "    return l\n",
    "verb_hao = read_file(\"sample-data/verb_hao.txt\")\n",
    "verb_dao = read_file(\"sample-data/verb_dao.txt\")\n",
    "verb_xialai = read_file(\"sample-data/verb_xialai.txt\")\n",
    "verb_xiaqu = read_file(\"sample-data/verb_xiaqu.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "# 디바이스 설정\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'bert-base-chinese'\n",
    "MAX_SIZE = 150\n",
    "BATCH_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)\n",
    "model = BertForMaskedLM.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentences) :\n",
    "    sent = []\n",
    "    label = []\n",
    "    for sentence in sentences : \n",
    "        s1 = sentence.split(\"<U>\")\n",
    "        s2 = s1[1].split(\"</U>\")\n",
    "        label.append(s2[0][-1])\n",
    "        sent.append(s1[0]+s2[0][:-1]+\"[MASK]\"+s2[1])\n",
    "        #debug\n",
    "#         print(s2[0][-1]) # label\n",
    "#         print(s1[0]+s2[0][:-1]+\"[MASK]\"+s2[1]) # sent\n",
    "    return sent, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_inference(sentences, top_n=5):\n",
    "    predicts = []\n",
    "    probabilities = []\n",
    "    for sentence in sentences:\n",
    "        input_ids = tokenizer(sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        mask_idx = input_ids.tolist()[0].index(103) #103 is [MASK] id\n",
    "        outputs = model(input_ids)\n",
    "        if top_n == 1:\n",
    "            logits = ouptuts[0].detach().numpy()\n",
    "            pred = tokenizer.convert_ids_to_tokens(np.argmax(logits, axis=2)[0])\n",
    "            predicts.append(pred[mask_idx])\n",
    "        else :\n",
    "            logits = outputs[0].detach()\n",
    "            mask_predict = F.softmax(logits[0][mask_idx], dim=0).numpy()\n",
    "            predict_top_n = mask_predict.argsort()[-top_n:][::-1]\n",
    "            predicts.append(tokenizer.convert_ids_to_tokens(predict_top_n))\n",
    "            probabilities.append(mask_predict[predict_top_n].tolist())\n",
    "    return predicts, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred, label):\n",
    "    cnt = 0\n",
    "    for p, l in zip(pred, label):\n",
    "        if p==l : \n",
    "            cnt += 1\n",
    "    return cnt / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data):\n",
    "    sent, label = preprocessing(data)\n",
    "    predict = inference(sent)\n",
    "    return evaluate(predict, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_softmax(data, top_n = 5, file_name=None):\n",
    "    sent, label = preprocessing(data)\n",
    "    pred, prob = softmax_inference(sent, top_n)\n",
    "    for sentence, candidates, probabilities, label in zip(sent, pred, prob, label):\n",
    "        print(sentence)\n",
    "        for c, p in zip(candidates,  probabilities):\n",
    "            print(\"{} : {:.2f}%\".format(c, p*100))\n",
    "        print(\"Answer : {}\".format(label))\n",
    "        print(\"\")\n",
    "    if file_name:\n",
    "        with open(file_name, \"w\") as f:\n",
    "            f.write(sentence)\n",
    "            for c, p in zip(candidates,  probabilities):\n",
    "                print(\"{} : {:.2f}%\".format(c, p*100))\n",
    "            f.write(\"Answer : {}\".format(label))\n",
    "            f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是约４２ｍｍ的遮光罩镜头外型尺寸为以说一尘不染，可见其密封性恨[MASK]。如此笔者发现独立镜头厂家适配０７２５ｘ１２２ｍｍ光学构造为１\n",
      "好 : 42.19%\n",
      "佳 : 19.26%\n",
      "强 : 11.28%\n",
      "高 : 6.79%\n",
      "差 : 4.63%\n",
      "Answer : 好\n",
      "\n",
      "很爱听，真像换了个脑筋，明年养多少头牛、羊都一家一户地帮我们算[MASK]了。”东湾乡大泉村二组村民马建雄忙着拉干部到自家去住，“干部住\n",
      "账 : 36.73%\n",
      "算 : 22.00%\n",
      "好 : 16.04%\n",
      "上 : 3.53%\n",
      "计 : 3.52%\n",
      "Answer : 好\n",
      "\n",
      "有关重大问题。第三，企业档案处置具体工作是收集、整理、统计、保管[MASK]企业已经形成的档案，清点库存，按有关规定做好档案留存与销毁的鉴\n",
      "各 : 36.24%\n",
      "本 : 35.96%\n",
      "该 : 4.26%\n",
      "好 : 3.60%\n",
      "在 : 1.77%\n",
      "Answer : 好\n",
      "\n",
      "策与财政政策的协调配合还体现为在经济发展的不同时期，两者都要搭配[MASK]。１９９８年下半年，财政为扩大内需，向国有商业银行增加发行１０\n",
      "好 : 76.31%\n",
      "住 : 6.40%\n",
      "上 : 3.82%\n",
      "合 : 3.16%\n",
      "着 : 2.46%\n",
      "Answer : 好\n",
      "\n",
      "政府贯彻〈中国教育改革和发展纲要〉的意见》。发展教育事业注意处理[MASK]三个关系：在数量和质量的关系上，更加重视质量；在德育和智育的关\n",
      "好 : 98.63%\n",
      "了 : 0.32%\n",
      "这 : 0.31%\n",
      "的 : 0.21%\n",
      "在 : 0.13%\n",
      "Answer : 好\n",
      "\n",
      "学管理的示范。一是要通过学习，增强创新创业的自觉性。要创业、干[MASK]事业，就必须抓重点、带全局。所有的人力、智力、财力、物力、科技\n",
      "好 : 93.29%\n",
      "大 : 3.46%\n",
      "新 : 1.15%\n",
      "事 : 0.48%\n",
      "实 : 0.42%\n",
      "Answer : 好\n",
      "\n",
      "解放思想，寻找经济快速发展的新路子。只有人的思想解放了，才能运用[MASK]中央制定的各项方针和政策，才能敢“闯”敢“新”，走出一条独特的\n",
      "好 : 85.65%\n",
      "党 : 11.48%\n",
      "住 : 1.81%\n",
      "新 : 0.28%\n",
      "了 : 0.15%\n",
      "Answer : 好\n",
      "\n",
      "到手术室，手术室大空间，手术床小范围，手术室到ＩＣＵ等各环节做[MASK]保温，避免外介温度的大波动引起婴儿不良反应。３．３减少患婴术中\n",
      "好 : 97.43%\n",
      "到 : 1.16%\n",
      "。 : 0.16%\n",
      "足 : 0.10%\n",
      "预 : 0.09%\n",
      "Answer : 好\n",
      "\n",
      "例如，在学习“如何做小主人和小客人”这一社会知识时，我们事先联系[MASK]一个家庭，并向主人详细讲解此次活动的目的、方法、步骤，以取得默\n",
      "了 : 41.96%\n",
      "上 : 14.96%\n",
      "好 : 12.51%\n",
      "到 : 11.31%\n",
      "每 : 4.08%\n",
      "Answer : 好\n",
      "\n",
      "切实加强农村信用社金融监管与行业管理的初步设想（一）必须正确处理[MASK]三大关系回、正确处理好信用社与联社的关系。基本原则是既要尊重信\n",
      "好 : 99.79%\n",
      "这 : 0.14%\n",
      "\" : 0.03%\n",
      "的 : 0.01%\n",
      "。 : 0.01%\n",
      "Answer : 好\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_softmax(verb_hao[:10], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Language model fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
