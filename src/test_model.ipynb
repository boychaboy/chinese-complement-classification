{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import softmax\n",
    "\n",
    "def run_inference5():\n",
    "    sent = input(\"Sentence(s) : \")\n",
    "    print(\"predicting...\")\n",
    "    labels = ['上去','下去','下来','出来','起来']\n",
    "    model = torch.load(\"../models/5_mac_large/5_mac_large.tar\")\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('hfl/chinese-macbert-large')\n",
    "    sent = sent.replace('！','。')\n",
    "    sent = sent.replace('？','。')\n",
    "    sents = sent.split('。')[:-1]\n",
    "    for sent in sents:\n",
    "        sent = sent.strip()\n",
    "        sent_ids = tokenizer(sent)['input_ids']\n",
    "        sent_tensor = torch.tensor(sent_ids).unsqueeze(0).to('cuda')\n",
    "        output = model(sent_tensor)[0]\n",
    "        logits =output.detach().cpu().numpy()[0]\n",
    "        predict = labels[np.argmax(logits, axis=0)]\n",
    "        softmax_output = softmax(output, 1)\n",
    "        print(sent)\n",
    "        print(f\"[MASK] : {predict}\")\n",
    "        result = dict()\n",
    "        for prob, label in zip(softmax_output[0].tolist(), labels):\n",
    "            result[label] = prob\n",
    "        print(f\"\\t出来 : {result['出来']*100:.2f}%\")\n",
    "        print(f\"\\t起来 : {result['起来']*100:.2f}%\")\n",
    "        print(f\"\\t上去 : {result['上去']*100:.2f}%\")\n",
    "        print(f\"\\t下来 : {result['下来']*100:.2f}%\")\n",
    "        print(f\"\\t下去 : {result['下去']*100:.2f}%\")        \n",
    "\n",
    "def run_inference8():\n",
    "    sent = input(\"Sentence(s) : \")\n",
    "    print(\"predicting...\")\n",
    "    labels = ['上去','下去','下来','出来','起来','上来','过来','过去']\n",
    "    model = torch.load(\"../models/8_mac_large/8_mac_large.tar\")\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('hfl/chinese-macbert-large')\n",
    "    sent = sent.replace('！','。')\n",
    "    sent = sent.replace('？','。')\n",
    "    sents = sent.split('。')[:-1]\n",
    "    for sent in sents:\n",
    "        sent = sent.strip()\n",
    "        sent_ids = tokenizer(sent)['input_ids']\n",
    "        sent_tensor = torch.tensor(sent_ids).unsqueeze(0).to('cuda')\n",
    "        output = model(sent_tensor)[0]\n",
    "        logits =output.detach().cpu().numpy()[0]\n",
    "        predict = labels[np.argmax(logits, axis=0)]\n",
    "        softmax_output = softmax(output, 1)\n",
    "        print(sent)\n",
    "        print(f\"[MASK] : {predict}\")\n",
    "        result = dict()\n",
    "        for prob, label in zip(softmax_output[0].tolist(), labels):\n",
    "            result[label] = prob\n",
    "        print(f\"\\t出来 : {result['出来']*100:.2f}%\")\n",
    "        print(f\"\\t过来 : {result['过来']*100:.2f}%\")\n",
    "        print(f\"\\t过去 : {result['过去']*100:.2f}%\")        \n",
    "        print(f\"\\t起来 : {result['起来']*100:.2f}%\")\n",
    "        print(f\"\\t上来 : {result['上来']*100:.2f}%\")   \n",
    "        print(f\"\\t上去 : {result['上去']*100:.2f}%\")\n",
    "        print(f\"\\t下来 : {result['下来']*100:.2f}%\")\n",
    "        print(f\"\\t下去 : {result['下去']*100:.2f}%\")\n",
    "\n",
    "def run_inference5_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        sents = f.readlines()\n",
    "    print(\"predicting...\")\n",
    "    labels = ['上去','下去','下来','出来','起来']\n",
    "    model = torch.load(\"../models/5_mac_large/5_mac_large.tar\")\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('hfl/chinese-macbert-large')\n",
    "\n",
    "    for sent in sents:\n",
    "        sent = sent.strip()\n",
    "        sent_ids = tokenizer(sent)['input_ids']\n",
    "        sent_tensor = torch.tensor(sent_ids).unsqueeze(0).to('cuda')\n",
    "        output = model(sent_tensor)[0]\n",
    "        logits =output.detach().cpu().numpy()[0]\n",
    "        predict = labels[np.argmax(logits, axis=0)]\n",
    "        softmax_output = softmax(output, 1)\n",
    "        print(sent)\n",
    "        print(f\"[MASK] : {predict}\")\n",
    "        result = dict()\n",
    "        for prob, label in zip(softmax_output[0].tolist(), labels):\n",
    "            result[label] = prob\n",
    "        print(f\"\\t出来 : {result['出来']*100:.2f}%\")\n",
    "        print(f\"\\t起来 : {result['起来']*100:.2f}%\")\n",
    "        print(f\"\\t上去 : {result['上去']*100:.2f}%\")\n",
    "        print(f\"\\t下来 : {result['下来']*100:.2f}%\")\n",
    "        print(f\"\\t下去 : {result['下去']*100:.2f}%\")            \n",
    "\n",
    "def run_inference8_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        sents = f.readlines()\n",
    "    print(\"predicting...\")\n",
    "    labels = ['上去','下去','下来','出来','起来','上来','过来','过去']\n",
    "    model = torch.load(\"../models/8_mac_large/8_mac_large.tar\")\n",
    "    model = model.to('cuda')\n",
    "    model.eval()\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('hfl/chinese-macbert-large')\n",
    "\n",
    "    for sent in sents:\n",
    "        sent = sent.strip()\n",
    "        sent_ids = tokenizer(sent)['input_ids']\n",
    "        sent_tensor = torch.tensor(sent_ids).unsqueeze(0).to('cuda')\n",
    "        output = model(sent_tensor)[0]\n",
    "        logits =output.detach().cpu().numpy()[0]\n",
    "        predict = labels[np.argmax(logits, axis=0)]\n",
    "        softmax_output = softmax(output, 1)\n",
    "        print(sent)\n",
    "        print(f\"[MASK] : {predict}\")\n",
    "        result = dict()\n",
    "        for prob, label in zip(softmax_output[0].tolist(), labels):\n",
    "            result[label] = prob\n",
    "        print(f\"\\t出来 : {result['出来']*100:.2f}%\")\n",
    "        print(f\"\\t过来 : {result['过来']*100:.2f}%\")\n",
    "        print(f\"\\t过去 : {result['过去']*100:.2f}%\")        \n",
    "        print(f\"\\t起来 : {result['起来']*100:.2f}%\")\n",
    "        print(f\"\\t上来 : {result['上来']*100:.2f}%\")   \n",
    "        print(f\"\\t上去 : {result['上去']*100:.2f}%\")\n",
    "        print(f\"\\t下来 : {result['下来']*100:.2f}%\")\n",
    "        print(f\"\\t下去 : {result['下去']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방향보어 5개 중에 1개 선택하기\n",
    "**예시 문장**  \n",
    "你是用什么办法把这种习惯坚持[MASK]的？    \n",
    "只要有信心，环境再残酷，也能坚持[MASK]。  \n",
    "这是一场梦，这地方我绝对不会再住[MASK]。  \n",
    "他的眼睛仍然望着窗外在旋转着的大地，心情有些沉重[MASK]。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence(s) : 你是用什么办法把这种习惯坚持[MASK]的？   只要有信心，环境再残酷，也能坚持[MASK]。  这是一场梦，这地方我绝对不会再住[MASK]。\n",
      "predicting...\n",
      "你是用什么办法把这种习惯坚持[MASK]的\n",
      "[MASK] : 下来\n",
      "\t出来 : 0.00%\n",
      "\t起来 : 0.00%\n",
      "\t上去 : 0.00%\n",
      "\t下来 : 99.26%\n",
      "\t下去 : 0.74%\n",
      "只要有信心，环境再残酷，也能坚持[MASK]\n",
      "[MASK] : 下去\n",
      "\t出来 : 0.00%\n",
      "\t起来 : 0.00%\n",
      "\t上去 : 0.00%\n",
      "\t下来 : 0.10%\n",
      "\t下去 : 99.89%\n",
      "这是一场梦，这地方我绝对不会再住[MASK]\n",
      "[MASK] : 下去\n",
      "\t出来 : 0.00%\n",
      "\t起来 : 0.00%\n",
      "\t上去 : 0.00%\n",
      "\t下来 : 0.00%\n",
      "\t下去 : 99.99%\n"
     ]
    }
   ],
   "source": [
    "run_inference5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방향보어 8개 중에 1개 \n",
    "你是用什么办法把这种习惯坚持[MASK]的？    \n",
    "只要有信心，环境再残酷，也能坚持[MASK]。  \n",
    "这是一场梦，这地方我绝对不会再住[MASK]。  \n",
    "他的眼睛仍然望着窗外在旋转着的大地，心情有些沉重[MASK]。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence(s) : 你是用什么办法把这种习惯坚持[MASK]的？ 只要有信心，环境再残酷，也能坚持[MASK]。 这是一场梦，这地方我绝对不会再住[MASK]。 他的眼睛仍然望着窗外在旋转着的大地，心情有些沉重[MASK]。\n",
      "predicting...\n",
      "你是用什么办法把这种习惯坚持[MASK]的\n",
      "[MASK] : 下来\n",
      "\t出来 : 0.00%\n",
      "\t过来 : 0.00%\n",
      "\t过去 : 0.00%\n",
      "\t起来 : 0.00%\n",
      "\t上来 : 0.00%\n",
      "\t上去 : 0.00%\n",
      "\t下来 : 99.98%\n",
      "\t下去 : 0.01%\n",
      "只要有信心，环境再残酷，也能坚持[MASK]\n",
      "[MASK] : 下去\n",
      "\t出来 : 0.00%\n",
      "\t过来 : 0.01%\n",
      "\t过去 : 0.07%\n",
      "\t起来 : 0.00%\n",
      "\t上来 : 0.00%\n",
      "\t上去 : 0.01%\n",
      "\t下来 : 0.51%\n",
      "\t下去 : 99.40%\n",
      "这是一场梦，这地方我绝对不会再住[MASK]\n",
      "[MASK] : 下去\n",
      "\t出来 : 0.00%\n",
      "\t过来 : 0.00%\n",
      "\t过去 : 0.00%\n",
      "\t起来 : 0.00%\n",
      "\t上来 : 0.00%\n",
      "\t上去 : 0.00%\n",
      "\t下来 : 0.00%\n",
      "\t下去 : 99.99%\n",
      "他的眼睛仍然望着窗外在旋转着的大地，心情有些沉重[MASK]\n",
      "[MASK] : 起来\n",
      "\t出来 : 0.00%\n",
      "\t过来 : 0.00%\n",
      "\t过去 : 0.00%\n",
      "\t起来 : 100.00%\n",
      "\t上来 : 0.00%\n",
      "\t上去 : 0.00%\n",
      "\t下来 : 0.00%\n",
      "\t下去 : 0.00%\n"
     ]
    }
   ],
   "source": [
    "run_inference8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
