{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis(data_dir):\n",
    "    label_dict = {'shanglai':'上来',\n",
    "                  'shangqu':'上去',\n",
    "                  'xialai':'下来',\n",
    "                  'xiaqu':'下去',\n",
    "                  'guolai':'过来',\n",
    "                  'guoqu':'过去',\n",
    "                  'qilai':'起来',\n",
    "                  'chulai':'出来'\n",
    "                 }\n",
    "    label_list = ['shanglai', 'shangqu', 'xialai', 'xiaqu', 'guolai', 'guoqu', 'qilai', 'chulai']\n",
    "    data = []\n",
    "    for label in label_list:\n",
    "        file_list = [data_dir+'/verb_'+label+'_literature.txt',\n",
    "                     data_dir+'/verb_'+label+'_media.txt',\n",
    "                     data_dir+'/verb_'+label+'_textbook.txt']\n",
    "        for file in file_list:\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.replace('？','。')\n",
    "                    line = line.replace('!','。')\n",
    "                    sent_list = line.split('。')\n",
    "                    for sent in sent_list:\n",
    "                        sent = sent.strip()\n",
    "                        if label_dict[label] in sent:\n",
    "                            sent = sent.replace(label_dict[label],'[MASK]', 1)\n",
    "                            data.append([sent, label_dict[label]])\n",
    "    avg_len = 0\n",
    "    for d in data:\n",
    "        avg_len+= len(d[0])\n",
    "    print(len(data))\n",
    "    print(avg_len)\n",
    "    print(avg_len/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120965\n",
      "6942395\n",
      "57.391766213367504\n"
     ]
    }
   ],
   "source": [
    "data_analysis('final8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final8\n",
    "def get_data8(data_dir):\n",
    "    mask_len = 100\n",
    "    label_dict = {'shanglai':'上来',\n",
    "                  'shangqu':'上去',\n",
    "                  'xialai':'下来',\n",
    "                  'xiaqu':'下去',\n",
    "                  'guolai':'过来',\n",
    "                  'guoqu':'过去',\n",
    "                  'qilai':'起来',\n",
    "                  'chulai':'出来'\n",
    "                 }\n",
    "    label_list = ['shanglai', 'shangqu', 'xialai', 'xiaqu', 'guolai', 'guoqu', 'qilai', 'chulai']\n",
    "    data = []\n",
    "    for label in label_list:\n",
    "        file_list = [data_dir+'/verb_'+label+'_literature.txt',\n",
    "                     data_dir+'/verb_'+label+'_media.txt',\n",
    "                     data_dir+'/verb_'+label+'_textbook.txt']\n",
    "        for file in file_list:\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.replace('？','。')\n",
    "                    line = line.replace('!','。')\n",
    "                    sent_list = line.split('。')\n",
    "                    for sent in sent_list:\n",
    "                        sent = sent.strip()[:mask_len]\n",
    "                        if label_dict[label] in sent:\n",
    "                            sent = sent.replace(label_dict[label],'[MASK]', 1)\n",
    "                            data.append([sent, label_dict[label]])\n",
    "    print(data[0])\n",
    "    print(f\"Number of data : {len(data)}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['因为他们三个深深知道满喜这个特点，所以都赶[MASK]向他赔情道歉；惹不起满以为自己的本事可以斗得过满喜，现在领了一下教也知道不行，所以也不敢再开口，可是满喜还没有放手', '上来']\n",
      "Number of data : 116769\n"
     ]
    }
   ],
   "source": [
    "data8 = get_data8('final8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final8\n",
    "def get_data5(data_dir):\n",
    "    mask_len = 100\n",
    "    label_dict = {\n",
    "                  'shangqu':'上去',\n",
    "                  'xialai':'下来',\n",
    "                  'xiaqu':'下去',\n",
    "                  'qilai':'起来',\n",
    "                  'chulai':'出来'\n",
    "                 }\n",
    "    label_list = ['shangqu', 'xialai', 'xiaqu', 'qilai', 'chulai']\n",
    "    data = []\n",
    "    for label in label_list:\n",
    "        file_list = [data_dir+'/verb_'+label+'_literature.txt',\n",
    "                     data_dir+'/verb_'+label+'_media.txt',\n",
    "                     data_dir+'/verb_'+label+'_textbook.txt']\n",
    "        for file in file_list:\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.replace('？','。')\n",
    "                    line = line.replace('!','。')\n",
    "                    sent_list = line.split('。')\n",
    "                    for sent in sent_list:\n",
    "                        sent = sent.strip()[:mask_len]\n",
    "                        if label_dict[label] in sent:\n",
    "                            sent = sent.replace(label_dict[label],'[MASK]', 1)\n",
    "                            data.append([sent, label_dict[label]])\n",
    "    print(data[0])\n",
    "    print(f\"Number of data : {len(data)}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeff金生说：“计划路线倒很容易，只是找个向导很困难——主要干部顾不[MASK]，一般社员说不明问题', '上去']\n",
      "Number of data : 99183\n"
     ]
    }
   ],
   "source": [
    "data5 = get_data5('final5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final4\n",
    "def get_data4(data_dir):\n",
    "    mask_len = 100\n",
    "    label_dict = {\n",
    "                  'xialai':'下来',\n",
    "                  'xiaqu':'下去',\n",
    "                  'qilai':'起来',\n",
    "                  'chulai':'出来'\n",
    "                 }\n",
    "    label_list = ['xialai', 'xiaqu', 'qilai', 'chulai']\n",
    "    data = []\n",
    "    for label in label_list:\n",
    "        file_list = [data_dir+'/verb_'+label+'_literature.txt',\n",
    "                     data_dir+'/verb_'+label+'_media.txt',\n",
    "                     data_dir+'/verb_'+label+'_textbook.txt']\n",
    "        for file in file_list:\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.replace('？','。')\n",
    "                    line = line.replace('!','。')\n",
    "                    sent_list = line.split('。')\n",
    "                    for sent in sent_list:\n",
    "                        sent = sent.strip()[:mask_len]\n",
    "                        if label_dict[label] in sent:\n",
    "                            sent = sent.replace(label_dict[label],'[MASK]', 1)\n",
    "                            data.append([sent, label_dict[label]])\n",
    "    print(data[0])\n",
    "    print(f\"Number of data : {len(data)}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['玉梅见她说上气来，很后悔自己不该先提起玉生媳妇，好容易等她说到一个段落上停[MASK]，正想用别的话岔开，忽听得南窑里有人说：“这是谁找谁的事呀', '下来']\n",
      "Number of data : 94327\n"
     ]
    }
   ],
   "source": [
    "data4 = get_data4('final4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_data(data, seed, rate):\n",
    "    # shuffle data\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # split data\n",
    "    data_len = len(data)\n",
    "    val_len = int(rate * data_len)\n",
    "    train_len = data_len - val_len\n",
    "    val_data = data[:val_len]\n",
    "    train_data = data[val_len:]\n",
    "    \n",
    "    return [train_data, val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data8, val_data8 = split_data(data8, 1, 0.1)\n",
    "train_data5, val_data5 = split_data(data5, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data4, val_data4 = split_data(data4, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump txt files\n",
    "def dump_txt(file, file_name):\n",
    "    with open(file_name+'.txt', 'w') as f:\n",
    "        for line in file:\n",
    "            sent = line[0].replace('[MASK]', line[1])\n",
    "            f.write(sent+'\\n')\n",
    "# dump_txt(train_data8, 'train8')\n",
    "# dump_txt(train_data5, 'train5')\n",
    "# dump_txt(val_data8, 'val8')\n",
    "# dump_txt(val_data5, 'val5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_txt(train_data4, 'train4')\n",
    "dump_txt(val_data4, 'val4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump json files\n",
    "import json\n",
    "def dump_json(file, file_name):\n",
    "    with open(file_name+'.json', 'w') as f:\n",
    "        json.dump(file, f)\n",
    "# dump_json(train_data8, 'train8')\n",
    "# dump_json(train_data5, 'train5')\n",
    "dump_json(train_data4, 'train4')\n",
    "# dump_json(val_data8, 'val8')\n",
    "# dump_json(val_data5, 'val5')\n",
    "dump_json(val_data4, 'val4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿被救[MASK]了,老师也没吵他,还忙将湿衣裳给他脱下来,将自己的大棉袄给他披上。\t上来\n",
      "Number of data : 8000\n",
      "﻿她全神贯注地等候，思量着从哪一边跳[MASK]。\t上去\n",
      "Number of data : 5000\n",
      "﻿他蹲[MASK],把兔子放在雪地上。\t下来\n",
      "Number of data : 4000\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "def get_test_data8(data_dir):\n",
    "    mask_len = 100\n",
    "    label_dict = {'shanglai':'上来',\n",
    "                  'shangqu':'上去',\n",
    "                  'xialai':'下来',\n",
    "                  'xiaqu':'下去',\n",
    "                  'guolai':'过来',\n",
    "                  'guoqu':'过去',\n",
    "                  'qilai':'起来',\n",
    "                  'chulai':'出来'\n",
    "                 }\n",
    "    label_list = ['shanglai', 'shangqu', 'xialai', 'xiaqu', 'guolai', 'guoqu', 'qilai', 'chulai']\n",
    "    data = []\n",
    "    for label in label_list:\n",
    "        file = data_dir+label+'.txt'\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                data.append(line.strip())\n",
    "    print(data[0])\n",
    "    print(f\"Number of data : {len(data)}\")\n",
    "    return data\n",
    "\n",
    "# test data\n",
    "def get_test_data5(data_dir):\n",
    "    mask_len = 100\n",
    "    label_dict = {\n",
    "                  'shangqu':'上去',\n",
    "                  'xialai':'下来',\n",
    "                  'xiaqu':'下去',\n",
    "                  'qilai':'起来',\n",
    "                  'chulai':'出来'\n",
    "                 }\n",
    "    label_list = ['shangqu', 'xialai', 'xiaqu', 'qilai', 'chulai']\n",
    "    data = []\n",
    "    for label in label_list:\n",
    "        file = data_dir+label+'.txt'\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                data.append(line.strip())\n",
    "    print(data[0])\n",
    "    print(f\"Number of data : {len(data)}\")\n",
    "    return data\n",
    "\n",
    "# test data 4\n",
    "def get_test_data4(data_dir):\n",
    "    mask_len = 100\n",
    "    label_dict = {\n",
    "                  'xialai':'下来',\n",
    "                  'xiaqu':'下去',\n",
    "                  'qilai':'起来',\n",
    "                  'chulai':'出来'\n",
    "                 }\n",
    "    label_list = ['xialai', 'xiaqu', 'qilai', 'chulai']\n",
    "    data = []\n",
    "    for label in label_list:\n",
    "        file = data_dir+label+'.txt'\n",
    "        with open(file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                data.append(line.strip())\n",
    "    print(data[0])\n",
    "    print(f\"Number of data : {len(data)}\")\n",
    "    return data\n",
    "\n",
    "test8 = get_test_data8('new_test8/')\n",
    "test5 = get_test_data5('new_test5/')\n",
    "test4 = get_test_data4('new_test4/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('new_test8.json', 'w') as f:\n",
    "    json.dump(test8, f)\n",
    "with open('new_test5.json', 'w') as f:\n",
    "    json.dump(test5, f)\n",
    "with open('new_test4.json', 'w') as f:\n",
    "    json.dump(test4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
